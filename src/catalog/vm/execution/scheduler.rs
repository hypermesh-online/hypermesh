//! Execution Scheduler - Consensus-aware task scheduling with asset optimization
//!
//! This scheduler coordinates execution tasks with asset allocation and consensus
//! validation requirements. It optimizes resource allocation across multiple
//! executions while maintaining consensus proof validation.

use std::sync::Arc;
use std::collections::{HashMap, VecDeque, BinaryHeap};
use std::time::{SystemTime, Duration, Instant};
use std::cmp::Ordering;
use anyhow::{Result, anyhow};
use serde::{Serialize, Deserialize};
use tokio::sync::{RwLock, Mutex, Semaphore};
use uuid::Uuid;

use crate::catalog::vm::consensus::{ConsensusVM, ConsensusOperation};
use crate::assets::core::{AssetType, AssetId};
use super::context::ExecutionContext;
use super::super::{AssetManagementConfig, ConsensusRequirements};

/// Execution scheduler with consensus-aware resource allocation
pub struct ExecutionScheduler {
    /// Consensus VM for validation
    consensus_vm: Arc<ConsensusVM>,
    /// Asset management configuration
    asset_config: AssetManagementConfig,
    /// Pending execution queue
    pending_queue: Arc<RwLock<BinaryHeap<ScheduledExecution>>>,
    /// Running executions tracker
    running_executions: Arc<RwLock<HashMap<String, RunningExecution>>>,
    /// Resource availability tracker
    resource_tracker: Arc<RwLock<ResourceTracker>>,
    /// Scheduler metrics
    metrics: Arc<Mutex<SchedulerMetrics>>,
    /// Concurrency limits
    execution_semaphore: Arc<Semaphore>,
    /// Configuration
    config: SchedulerConfig,
}

/// Execution plan generated by scheduler
#[derive(Debug, Clone)]
pub struct ExecutionPlan {
    /// Unique execution identifier
    pub execution_id: String,
    /// Code to execute
    pub code: String,
    /// Programming language
    pub language: String,
    /// Required asset allocations
    pub required_assets: HashMap<AssetType, u64>,
    /// Consensus operation for validation
    pub consensus_operation: ConsensusOperation,
    /// Execution priority
    pub priority: ExecutionPriority,
    /// Estimated execution time
    pub estimated_duration: Duration,
    /// Resource optimization strategy
    pub optimization_strategy: OptimizationStrategy,
    /// Execution constraints
    pub constraints: ExecutionConstraints,
}

/// Scheduled execution with priority queue ordering
#[derive(Debug, Clone)]
pub struct ScheduledExecution {
    /// Execution plan
    pub plan: ExecutionPlan,
    /// Execution context
    pub context: Arc<ExecutionContext>,
    /// Scheduled timestamp
    pub scheduled_at: SystemTime,
    /// Execution deadline (optional)
    pub deadline: Option<SystemTime>,
    /// Scheduling priority score
    pub priority_score: f64,
}

impl PartialEq for ScheduledExecution {
    fn eq(&self, other: &Self) -> bool {
        self.priority_score.partial_cmp(&other.priority_score) == Some(Ordering::Equal)
    }
}

impl Eq for ScheduledExecution {}

impl PartialOrd for ScheduledExecution {
    fn partial_cmp(&self, other: &Self) -> Option<Ordering> {
        // Higher priority scores come first
        other.priority_score.partial_cmp(&self.priority_score)
    }
}

impl Ord for ScheduledExecution {
    fn cmp(&self, other: &Self) -> Ordering {
        self.partial_cmp(other).unwrap_or(Ordering::Equal)
    }
}

/// Running execution tracker
#[derive(Debug, Clone)]
pub struct RunningExecution {
    pub execution_id: String,
    pub started_at: SystemTime,
    pub estimated_completion: SystemTime,
    pub allocated_resources: HashMap<AssetType, u64>,
    pub context: Arc<ExecutionContext>,
}

/// Resource availability tracker
#[derive(Debug, Default)]
pub struct ResourceTracker {
    /// Available CPU cores
    pub available_cpu_cores: u32,
    /// Available memory (bytes)
    pub available_memory: u64,
    /// Available GPU cores
    pub available_gpu_cores: u32,
    /// Available storage (bytes)
    pub available_storage: u64,
    /// Available network bandwidth (bytes/sec)
    pub available_bandwidth: u64,
    /// Resource reservations
    pub reservations: HashMap<String, ResourceReservation>,
}

/// Resource reservation for scheduled executions
#[derive(Debug, Clone)]
pub struct ResourceReservation {
    pub execution_id: String,
    pub reserved_resources: HashMap<AssetType, u64>,
    pub reservation_expires: SystemTime,
}

/// Execution priority levels
#[derive(Debug, Clone, PartialEq, Eq, PartialOrd, Ord, Serialize, Deserialize)]
pub enum ExecutionPriority {
    Low = 1,
    Normal = 2,
    High = 3,
    Critical = 4,
    Emergency = 5,
}

impl Default for ExecutionPriority {
    fn default() -> Self {
        ExecutionPriority::Normal
    }
}

/// Resource optimization strategies
#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum OptimizationStrategy {
    /// Minimize execution time
    Speed,
    /// Minimize resource usage
    Efficiency,
    /// Balance speed and efficiency
    Balanced,
    /// Maximize resource utilization
    Throughput,
    /// Custom optimization parameters
    Custom(OptimizationParameters),
}

/// Custom optimization parameters
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct OptimizationParameters {
    pub cpu_weight: f64,
    pub memory_weight: f64,
    pub gpu_weight: f64,
    pub network_weight: f64,
    pub latency_weight: f64,
    pub throughput_weight: f64,
}

/// Execution constraints
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ExecutionConstraints {
    /// Maximum execution time allowed
    pub max_execution_time: Option<Duration>,
    /// Maximum memory usage
    pub max_memory_usage: Option<u64>,
    /// Maximum CPU cores
    pub max_cpu_cores: Option<u32>,
    /// Minimum consensus validation level
    pub min_consensus_level: ConsensusValidationLevel,
    /// Required asset isolation
    pub asset_isolation: AssetIsolationLevel,
}

/// Consensus validation levels
#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum ConsensusValidationLevel {
    Basic,      // Single proof validation
    Standard,   // Two proof validation
    Enhanced,   // Three proof validation
    Complete,   // All four proof validation
}

/// Asset isolation levels
#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum AssetIsolationLevel {
    None,       // Shared resources
    Process,    // Process-level isolation
    Container,  // Container-level isolation
    VM,         // Virtual machine isolation
    Hardware,   // Hardware-level isolation
}

/// Scheduler configuration
#[derive(Debug, Clone)]
pub struct SchedulerConfig {
    /// Maximum concurrent executions
    pub max_concurrent_executions: u32,
    /// Scheduling quantum (time slice)
    pub scheduling_quantum: Duration,
    /// Resource over-subscription ratio
    pub oversubscription_ratio: f64,
    /// Priority aging factor
    pub priority_aging_factor: f64,
    /// Deadline urgency factor
    pub deadline_urgency_factor: f64,
    /// Enable resource preemption
    pub enable_preemption: bool,
}

impl Default for SchedulerConfig {
    fn default() -> Self {
        Self {
            max_concurrent_executions: 10,
            scheduling_quantum: Duration::from_millis(100),
            oversubscription_ratio: 1.2,
            priority_aging_factor: 0.1,
            deadline_urgency_factor: 2.0,
            enable_preemption: false,
        }
    }
}

/// Scheduler performance metrics
#[derive(Debug, Default)]
pub struct SchedulerMetrics {
    pub total_scheduled: u64,
    pub total_completed: u64,
    pub total_failed: u64,
    pub average_wait_time: Duration,
    pub average_execution_time: Duration,
    pub resource_utilization: HashMap<AssetType, f64>,
    pub queue_length: usize,
    pub preemptions: u64,
}

impl ExecutionScheduler {
    /// Create new execution scheduler
    pub async fn new(
        consensus_vm: Arc<ConsensusVM>,
        asset_config: AssetManagementConfig,
    ) -> Result<Self> {
        let config = SchedulerConfig::default();
        let execution_semaphore = Arc::new(Semaphore::new(config.max_concurrent_executions as usize));
        
        Ok(Self {
            consensus_vm,
            asset_config,
            pending_queue: Arc::new(RwLock::new(BinaryHeap::new())),
            running_executions: Arc::new(RwLock::new(HashMap::new())),
            resource_tracker: Arc::new(RwLock::new(ResourceTracker::default())),
            metrics: Arc::new(Mutex::new(SchedulerMetrics::default())),
            execution_semaphore,
            config,
        })
    }
    
    /// Schedule execution with consensus validation
    pub async fn schedule_execution(
        &self,
        consensus_operation: &ConsensusOperation,
        context: &Arc<ExecutionContext>,
        code: &str,
    ) -> Result<ExecutionPlan> {
        let execution_id = Uuid::new_v4().to_string();
        
        // Analyze resource requirements
        let required_assets = self.analyze_resource_requirements(code, &context.language).await?;
        
        // Estimate execution duration
        let estimated_duration = self.estimate_execution_duration(
            code,
            &context.language,
            &required_assets,
        ).await?;
        
        // Determine optimization strategy
        let optimization_strategy = self.determine_optimization_strategy(context).await?;
        
        // Create execution constraints
        let constraints = self.create_execution_constraints(context).await?;
        
        // Calculate priority score
        let priority = self.determine_execution_priority(context).await?;
        let priority_score = self.calculate_priority_score(&priority, context).await?;
        
        // Create execution plan
        let execution_plan = ExecutionPlan {
            execution_id: execution_id.clone(),
            code: code.to_string(),
            language: context.language.clone(),
            required_assets,
            consensus_operation: consensus_operation.clone(),
            priority,
            estimated_duration,
            optimization_strategy,
            constraints,
        };
        
        // Create scheduled execution
        let scheduled_execution = ScheduledExecution {
            plan: execution_plan.clone(),
            context: Arc::clone(context),
            scheduled_at: SystemTime::now(),
            deadline: self.calculate_deadline(context).await?,
            priority_score,
        };
        
        // Add to pending queue
        {
            let mut queue = self.pending_queue.write().await;
            queue.push(scheduled_execution);
        }
        
        // Update metrics
        {
            let mut metrics = self.metrics.lock().await;
            metrics.total_scheduled += 1;
            metrics.queue_length = {
                let queue = self.pending_queue.read().await;
                queue.len()
            };
        }
        
        // Trigger scheduling cycle
        self.trigger_scheduling_cycle().await?;
        
        Ok(execution_plan)
    }
    
    /// Analyze resource requirements for code execution
    async fn analyze_resource_requirements(
        &self,
        code: &str,
        language: &str,
    ) -> Result<HashMap<AssetType, u64>> {
        let mut requirements = HashMap::new();
        
        // Base resource requirements by language
        match language.to_lowercase().as_str() {
            "julia" => {
                requirements.insert(AssetType::Cpu, 2); // 2 CPU cores
                requirements.insert(AssetType::Memory, 1024 * 1024 * 1024); // 1GB RAM
                
                // Check for GPU operations
                if code.contains("Nova") || code.contains("GPU") {
                    requirements.insert(AssetType::Gpu, 1);
                }
            },
            "python" => {
                requirements.insert(AssetType::Cpu, 1); // 1 CPU core
                requirements.insert(AssetType::Memory, 512 * 1024 * 1024); // 512MB RAM
                
                // Check for machine learning libraries
                if code.contains("torch") || code.contains("tensorflow") {
                    requirements.insert(AssetType::Gpu, 1);
                    requirements.insert(AssetType::Memory, 2 * 1024 * 1024 * 1024); // 2GB RAM
                }
            },
            "rust" => {
                requirements.insert(AssetType::Cpu, 1); // 1 CPU core
                requirements.insert(AssetType::Memory, 256 * 1024 * 1024); // 256MB RAM
            },
            _ => {
                // Default requirements
                requirements.insert(AssetType::Cpu, 1);
                requirements.insert(AssetType::Memory, 512 * 1024 * 1024);
            }
        }
        
        // Analyze code complexity for additional requirements
        let code_size = code.len();
        if code_size > 10000 {
            // Large code may need more resources
            if let Some(memory) = requirements.get_mut(&AssetType::Memory) {
                *memory = (*memory as f64 * 1.5) as u64;
            }
        }
        
        // Check for storage operations
        if code.contains("file") || code.contains("read") || code.contains("write") {
            requirements.insert(AssetType::Storage, 100 * 1024 * 1024); // 100MB storage
        }
        
        Ok(requirements)
    }
    
    /// Estimate execution duration based on code and resource requirements
    async fn estimate_execution_duration(
        &self,
        code: &str,
        language: &str,
        required_assets: &HashMap<AssetType, u64>,
    ) -> Result<Duration> {
        // Base estimation by language and code complexity
        let code_lines = code.lines().count();
        let code_complexity = self.analyze_code_complexity(code, language).await?;
        
        let base_duration = match language.to_lowercase().as_str() {
            "julia" => Duration::from_millis(100 + code_lines as u64 * 10),
            "python" => Duration::from_millis(200 + code_lines as u64 * 20),
            "rust" => Duration::from_millis(50 + code_lines as u64 * 5),
            _ => Duration::from_millis(150 + code_lines as u64 * 15),
        };
        
        // Adjust for complexity
        let complexity_factor = match code_complexity {
            CodeComplexity::Low => 1.0,
            CodeComplexity::Medium => 2.0,
            CodeComplexity::High => 5.0,
            CodeComplexity::VeryHigh => 10.0,
        };
        
        // Adjust for resource availability
        let resource_factor = self.calculate_resource_availability_factor(required_assets).await?;
        
        Ok(Duration::from_nanos(
            (base_duration.as_nanos() as f64 * complexity_factor * resource_factor) as u64
        ))
    }
    
    /// Analyze code complexity
    async fn analyze_code_complexity(&self, code: &str, language: &str) -> Result<CodeComplexity> {
        let mut complexity_score = 0;
        
        // Count loops
        complexity_score += code.matches("for").count() * 2;
        complexity_score += code.matches("while").count() * 3;
        
        // Count conditionals
        complexity_score += code.matches("if").count();
        complexity_score += code.matches("match").count() * 2;
        
        // Count function definitions
        complexity_score += code.matches("function").count();
        complexity_score += code.matches("def ").count();
        complexity_score += code.matches("fn ").count();
        
        // Count complex operations
        complexity_score += code.matches("sort").count() * 3;
        complexity_score += code.matches("search").count() * 2;
        complexity_score += code.matches("parallel").count() * 5;
        
        // Language-specific complexity
        match language.to_lowercase().as_str() {
            "julia" => {
                complexity_score += code.matches("@parallel").count() * 10;
                complexity_score += code.matches("@distributed").count() * 15;
            },
            "python" => {
                complexity_score += code.matches("multiprocessing").count() * 8;
                complexity_score += code.matches("threading").count() * 6;
            },
            "rust" => {
                complexity_score += code.matches("async").count() * 4;
                complexity_score += code.matches("await").count() * 2;
            },
            _ => {}
        }
        
        Ok(match complexity_score {
            0..=5 => CodeComplexity::Low,
            6..=15 => CodeComplexity::Medium,
            16..=50 => CodeComplexity::High,
            _ => CodeComplexity::VeryHigh,
        })
    }
    
    /// Calculate resource availability factor for execution time estimation
    async fn calculate_resource_availability_factor(
        &self,
        required_assets: &HashMap<AssetType, u64>,
    ) -> Result<f64> {
        let resource_tracker = self.resource_tracker.read().await;
        let mut availability_factor = 1.0;
        
        for (asset_type, required_amount) in required_assets {
            let available_amount = match asset_type {
                AssetType::Cpu => resource_tracker.available_cpu_cores as u64,
                AssetType::Memory => resource_tracker.available_memory,
                AssetType::Gpu => resource_tracker.available_gpu_cores as u64,
                AssetType::Storage => resource_tracker.available_storage,
                AssetType::Network => resource_tracker.available_bandwidth,
                AssetType::Container => 100, // Assume containers are lightweight
            };
            
            if available_amount > 0 {
                let utilization = *required_amount as f64 / available_amount as f64;
                if utilization > 0.8 {
                    // High utilization increases execution time
                    availability_factor *= 1.0 + (utilization - 0.8) * 3.0;
                }
            } else {
                // No resources available - significant delay
                availability_factor *= 5.0;
            }
        }
        
        Ok(availability_factor)
    }
    
    /// Determine optimization strategy based on context
    async fn determine_optimization_strategy(
        &self,
        context: &ExecutionContext,
    ) -> Result<OptimizationStrategy> {
        // In production: analyze context preferences and system state
        Ok(OptimizationStrategy::Balanced)
    }
    
    /// Create execution constraints based on context
    async fn create_execution_constraints(
        &self,
        context: &ExecutionContext,
    ) -> Result<ExecutionConstraints> {
        Ok(ExecutionConstraints {
            max_execution_time: Some(Duration::from_secs(300)), // 5 minutes default
            max_memory_usage: Some(4 * 1024 * 1024 * 1024), // 4GB default
            max_cpu_cores: Some(8), // 8 cores default
            min_consensus_level: ConsensusValidationLevel::Complete,
            asset_isolation: AssetIsolationLevel::Process,
        })
    }
    
    /// Determine execution priority based on context
    async fn determine_execution_priority(
        &self,
        context: &ExecutionContext,
    ) -> Result<ExecutionPriority> {
        // In production: analyze context metadata, user preferences, system load
        Ok(ExecutionPriority::Normal)
    }
    
    /// Calculate priority score for queue ordering
    async fn calculate_priority_score(
        &self,
        priority: &ExecutionPriority,
        context: &ExecutionContext,
    ) -> Result<f64> {
        let mut score = *priority as u8 as f64 * 100.0;
        
        // Add aging factor for waiting time
        // In production: calculate actual wait time
        score += 10.0;
        
        // Add urgency for deadline proximity
        // In production: calculate deadline urgency
        score += 5.0;
        
        Ok(score)
    }
    
    /// Calculate execution deadline
    async fn calculate_deadline(
        &self,
        context: &ExecutionContext,
    ) -> Result<Option<SystemTime>> {
        // In production: extract deadline from context or set based on priority
        Ok(Some(SystemTime::now() + Duration::from_secs(3600))) // 1 hour default
    }
    
    /// Trigger scheduling cycle to process pending executions
    async fn trigger_scheduling_cycle(&self) -> Result<()> {
        // This would be implemented as a background task in production
        // For now, just log that scheduling was triggered
        tracing::debug!("Scheduling cycle triggered");
        Ok(())
    }
    
    /// Get scheduler metrics
    pub async fn get_metrics(&self) -> SchedulerMetrics {
        let metrics = self.metrics.lock().await;
        metrics.clone()
    }
    
    /// Get pending queue status
    pub async fn get_queue_status(&self) -> QueueStatus {
        let queue = self.pending_queue.read().await;
        let running = self.running_executions.read().await;
        
        QueueStatus {
            pending_count: queue.len(),
            running_count: running.len(),
            total_capacity: self.config.max_concurrent_executions,
            next_execution_eta: queue.peek().map(|exec| exec.scheduled_at),
        }
    }
    
    /// Update resource availability
    pub async fn update_resource_availability(
        &self,
        available_cpu: u32,
        available_memory: u64,
        available_gpu: u32,
        available_storage: u64,
        available_bandwidth: u64,
    ) -> Result<()> {
        let mut tracker = self.resource_tracker.write().await;
        tracker.available_cpu_cores = available_cpu;
        tracker.available_memory = available_memory;
        tracker.available_gpu_cores = available_gpu;
        tracker.available_storage = available_storage;
        tracker.available_bandwidth = available_bandwidth;
        Ok(())
    }
}

/// Code complexity levels
#[derive(Debug, Clone)]
enum CodeComplexity {
    Low,
    Medium,
    High,
    VeryHigh,
}

/// Queue status information
#[derive(Debug, Clone)]
pub struct QueueStatus {
    pub pending_count: usize,
    pub running_count: usize,
    pub total_capacity: u32,
    pub next_execution_eta: Option<SystemTime>,
}

impl Clone for SchedulerMetrics {
    fn clone(&self) -> Self {
        Self {
            total_scheduled: self.total_scheduled,
            total_completed: self.total_completed,
            total_failed: self.total_failed,
            average_wait_time: self.average_wait_time,
            average_execution_time: self.average_execution_time,
            resource_utilization: self.resource_utilization.clone(),
            queue_length: self.queue_length,
            preemptions: self.preemptions,
        }
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use crate::consensus::ConsensusVM;
    
    #[tokio::test]
    async fn test_scheduler_creation() {
        let requirements = ConsensusRequirements::default();
        let consensus_vm = Arc::new(ConsensusVM::new(requirements).unwrap());
        let asset_config = AssetManagementConfig::default();
        
        let scheduler = ExecutionScheduler::new(consensus_vm, asset_config).await;
        assert!(scheduler.is_ok());
    }
    
    #[tokio::test]
    async fn test_resource_requirements_analysis() {
        let requirements = ConsensusRequirements::default();
        let consensus_vm = Arc::new(ConsensusVM::new(requirements).unwrap());
        let asset_config = AssetManagementConfig::default();
        let scheduler = ExecutionScheduler::new(consensus_vm, asset_config).await.unwrap();
        
        let julia_code = "using Nova\nfor i in 1:1000\n    println(i)\nend";
        let requirements = scheduler.analyze_resource_requirements(julia_code, "julia").await.unwrap();
        
        assert!(requirements.contains_key(&AssetType::Cpu));
        assert!(requirements.contains_key(&AssetType::Memory));
        assert!(requirements.contains_key(&AssetType::Gpu)); // Due to Nova
    }
    
    #[tokio::test]
    async fn test_code_complexity_analysis() {
        let requirements = ConsensusRequirements::default();
        let consensus_vm = Arc::new(ConsensusVM::new(requirements).unwrap());
        let asset_config = AssetManagementConfig::default();
        let scheduler = ExecutionScheduler::new(consensus_vm, asset_config).await.unwrap();
        
        let simple_code = "println(\"Hello, World!\")";
        let complexity = scheduler.analyze_code_complexity(simple_code, "julia").await.unwrap();
        assert!(matches!(complexity, CodeComplexity::Low));
        
        let complex_code = "for i in 1:1000\n    for j in 1:1000\n        if i > j\n            function complex_calc(x)\n                sort([x, x+1, x-1])\n            end\n        end\n    end\nend";
        let complexity = scheduler.analyze_code_complexity(complex_code, "julia").await.unwrap();
        assert!(matches!(complexity, CodeComplexity::High | CodeComplexity::VeryHigh));
    }
    
    #[tokio::test]
    async fn test_execution_priority_ordering() {
        let exec1 = ScheduledExecution {
            plan: ExecutionPlan {
                execution_id: "1".to_string(),
                code: "test".to_string(),
                language: "julia".to_string(),
                required_assets: HashMap::new(),
                consensus_operation: ConsensusOperation::default(),
                priority: ExecutionPriority::Low,
                estimated_duration: Duration::from_secs(10),
                optimization_strategy: OptimizationStrategy::Balanced,
                constraints: ExecutionConstraints {
                    max_execution_time: None,
                    max_memory_usage: None,
                    max_cpu_cores: None,
                    min_consensus_level: ConsensusValidationLevel::Complete,
                    asset_isolation: AssetIsolationLevel::Process,
                },
            },
            context: Arc::new(ExecutionContext::default()),
            scheduled_at: SystemTime::now(),
            deadline: None,
            priority_score: 100.0,
        };
        
        let exec2 = ScheduledExecution {
            plan: ExecutionPlan {
                execution_id: "2".to_string(),
                code: "test".to_string(),
                language: "julia".to_string(),
                required_assets: HashMap::new(),
                consensus_operation: ConsensusOperation::default(),
                priority: ExecutionPriority::High,
                estimated_duration: Duration::from_secs(10),
                optimization_strategy: OptimizationStrategy::Balanced,
                constraints: ExecutionConstraints {
                    max_execution_time: None,
                    max_memory_usage: None,
                    max_cpu_cores: None,
                    min_consensus_level: ConsensusValidationLevel::Complete,
                    asset_isolation: AssetIsolationLevel::Process,
                },
            },
            context: Arc::new(ExecutionContext::default()),
            scheduled_at: SystemTime::now(),
            deadline: None,
            priority_score: 300.0,
        };
        
        assert!(exec2 > exec1); // Higher priority score should come first
    }
}