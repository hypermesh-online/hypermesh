//! Catalog-HyperMesh Integration Bridge
//!
//! This module bridges the Catalog system with HyperMesh's VM and container runtime,
//! enabling Catalog assets to be deployed as containers or VM executions with
//! full consensus validation and resource management.

use std::sync::Arc;
use std::collections::HashMap;
use std::time::{SystemTime, Duration};
use anyhow::{Result, anyhow};
use serde::{Serialize, Deserialize};
use tokio::sync::{RwLock, Mutex};
use uuid::Uuid;

use crate::catalog::vm::{ConsensusProofVM, VMConfig, ExecutionContext, ExecutionResult};
use crate::orchestration::hypermesh_integration::{
    HyperMeshContainerOrchestrator, HyperMeshContainerSpec, ContainerDeploymentResult,
    AssetRequirements, PrivacyRequirements, PerformanceRequirements, ContainerMetadata,
};
use crate::assets::core::{AssetType, AssetId, ConsensusProof};
use crate::container::{ContainerSpec, ResourceRequirements};

/// Catalog asset types that can be deployed
#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum CatalogAssetType {
    /// Julia computation script
    JuliaScript {
        code: String,
        dependencies: Vec<String>,
        entry_point: String,
    },
    /// Python application
    PythonApp {
        code: String,
        requirements_txt: String,
        entry_point: String,
    },
    /// Rust binary
    RustBinary {
        source_code: String,
        cargo_toml: String,
        target: String,
    },
    /// Container image
    ContainerImage {
        image_name: String,
        image_tag: String,
        registry_url: String,
        dockerfile: Option<String>,
    },
    /// WebAssembly module
    WasmModule {
        wasm_bytes: Vec<u8>,
        metadata: WasmMetadata,
    },
    /// Data processing pipeline
    DataPipeline {
        stages: Vec<PipelineStage>,
        data_sources: Vec<DataSource>,
        outputs: Vec<DataOutput>,
    },
}

/// WebAssembly module metadata
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct WasmMetadata {
    pub module_name: String,
    pub version: String,
    pub exports: Vec<String>,
    pub imports: Vec<String>,
    pub memory_requirements: u64,
}

/// Data pipeline stage
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct PipelineStage {
    pub stage_id: String,
    pub stage_type: StageType,
    pub configuration: serde_json::Value,
    pub dependencies: Vec<String>,
}

/// Pipeline stage types
#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum StageType {
    DataIngestion,
    DataTransformation,
    DataValidation,
    DataAggregation,
    DataOutput,
    MachineLearning,
    CustomProcessing(String),
}

/// Data source configuration
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct DataSource {
    pub source_id: String,
    pub source_type: DataSourceType,
    pub connection_config: serde_json::Value,
    pub schema: Option<DataSchema>,
}

/// Data source types
#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum DataSourceType {
    Database,
    FileSystem,
    S3,
    Stream,
    API,
    Blockchain,
    Custom(String),
}

/// Data schema definition
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct DataSchema {
    pub fields: Vec<SchemaField>,
    pub constraints: Vec<DataConstraint>,
}

/// Schema field definition
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct SchemaField {
    pub name: String,
    pub field_type: FieldType,
    pub nullable: bool,
    pub description: Option<String>,
}

/// Field types
#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum FieldType {
    String,
    Integer,
    Float,
    Boolean,
    DateTime,
    Json,
    Binary,
    Custom(String),
}

/// Data constraints
#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum DataConstraint {
    Required(String),
    Unique(String),
    Range(String, f64, f64),
    Pattern(String, String),
    Custom(String, serde_json::Value),
}

/// Data output configuration
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct DataOutput {
    pub output_id: String,
    pub output_type: DataOutputType,
    pub destination_config: serde_json::Value,
    pub format: DataFormat,
}

/// Data output types
#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum DataOutputType {
    Database,
    FileSystem,
    S3,
    Stream,
    API,
    Blockchain,
    Custom(String),
}

/// Data formats
#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum DataFormat {
    Json,
    Csv,
    Parquet,
    Avro,
    Binary,
    Custom(String),
}

/// Catalog asset deployment specification
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct CatalogDeploymentSpec {
    /// Asset to deploy
    pub asset: CatalogAssetType,
    /// Deployment strategy
    pub deployment_strategy: DeploymentStrategy,
    /// Resource requirements
    pub resource_requirements: CatalogResourceRequirements,
    /// Privacy and security settings
    pub privacy_settings: CatalogPrivacySettings,
    /// Execution configuration
    pub execution_config: ExecutionConfiguration,
    /// Monitoring and observability
    pub monitoring_config: MonitoringConfiguration,
}

/// Deployment strategies
#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum DeploymentStrategy {
    /// Deploy as VM execution
    VMExecution {
        vm_config: VMDeploymentConfig,
    },
    /// Deploy as container
    Container {
        container_config: ContainerDeploymentConfig,
    },
    /// Deploy as serverless function
    Serverless {
        function_config: FunctionDeploymentConfig,
    },
    /// Hybrid deployment (VM + Container)
    Hybrid {
        vm_config: VMDeploymentConfig,
        container_config: ContainerDeploymentConfig,
    },
}

/// VM deployment configuration
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct VMDeploymentConfig {
    pub language_runtime: String,
    pub execution_timeout: Duration,
    pub memory_limit: u64,
    pub cpu_limit: u32,
    pub enable_gpu: bool,
    pub environment_variables: HashMap<String, String>,
}

/// Container deployment configuration
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ContainerDeploymentConfig {
    pub base_image: String,
    pub ports: Vec<PortMapping>,
    pub volumes: Vec<VolumeMount>,
    pub environment_variables: HashMap<String, String>,
    pub command: Vec<String>,
    pub args: Vec<String>,
}

/// Port mapping for containers
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct PortMapping {
    pub container_port: u16,
    pub host_port: Option<u16>,
    pub protocol: String,
}

/// Volume mount for containers
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct VolumeMount {
    pub source: String,
    pub destination: String,
    pub read_only: bool,
}

/// Function deployment configuration
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct FunctionDeploymentConfig {
    pub runtime: String,
    pub handler: String,
    pub timeout: Duration,
    pub memory_size: u64,
    pub triggers: Vec<FunctionTrigger>,
}

/// Function triggers
#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum FunctionTrigger {
    Http { path: String, methods: Vec<String> },
    Timer { schedule: String },
    Queue { queue_name: String },
    Event { event_type: String },
}

/// Resource requirements for catalog assets
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct CatalogResourceRequirements {
    pub cpu_cores: Option<u32>,
    pub memory_mb: Option<u64>,
    pub storage_gb: Option<u64>,
    pub gpu_count: Option<u32>,
    pub network_bandwidth_mbps: Option<u64>,
    pub custom_resources: HashMap<String, u64>,
}

/// Privacy settings for catalog deployments
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct CatalogPrivacySettings {
    pub data_privacy_level: DataPrivacyLevel,
    pub execution_privacy_level: ExecutionPrivacyLevel,
    pub network_isolation: bool,
    pub encrypt_at_rest: bool,
    pub encrypt_in_transit: bool,
    pub access_control_policies: Vec<AccessPolicy>,
}

/// Data privacy levels
#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum DataPrivacyLevel {
    Public,
    Internal,
    Confidential,
    Restricted,
    TopSecret,
}

/// Execution privacy levels
#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum ExecutionPrivacyLevel {
    Open,
    Isolated,
    Sandboxed,
    Encrypted,
    SecureEnclave,
}

/// Access control policies
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct AccessPolicy {
    pub policy_id: String,
    pub subjects: Vec<String>,
    pub permissions: Vec<Permission>,
    pub conditions: Vec<AccessCondition>,
}

/// Permissions
#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum Permission {
    Read,
    Write,
    Execute,
    Delete,
    Admin,
    Custom(String),
}

/// Access conditions
#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum AccessCondition {
    TimeRange { start: SystemTime, end: SystemTime },
    Location { allowed_locations: Vec<String> },
    Network { allowed_networks: Vec<String> },
    Custom(String, serde_json::Value),
}

/// Execution configuration
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ExecutionConfiguration {
    pub max_execution_time: Duration,
    pub retry_policy: RetryPolicy,
    pub scaling_policy: ScalingPolicy,
    pub failure_handling: FailureHandling,
    pub checkpoint_policy: CheckpointPolicy,
}

/// Retry policies
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct RetryPolicy {
    pub max_retries: u32,
    pub retry_delay: Duration,
    pub backoff_strategy: BackoffStrategy,
    pub retry_conditions: Vec<RetryCondition>,
}

/// Backoff strategies
#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum BackoffStrategy {
    Fixed,
    Linear,
    Exponential,
    Custom(f64),
}

/// Retry conditions
#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum RetryCondition {
    TransientError,
    ResourceUnavailable,
    TimeoutError,
    Custom(String),
}

/// Scaling policies
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ScalingPolicy {
    pub min_instances: u32,
    pub max_instances: u32,
    pub target_utilization: f64,
    pub scale_up_threshold: f64,
    pub scale_down_threshold: f64,
    pub scale_up_delay: Duration,
    pub scale_down_delay: Duration,
}

/// Failure handling strategies
#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum FailureHandling {
    Ignore,
    Restart,
    Failover,
    Alert,
    Custom(String),
}

/// Checkpoint policies
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct CheckpointPolicy {
    pub enable_checkpoints: bool,
    pub checkpoint_interval: Duration,
    pub max_checkpoints: u32,
    pub checkpoint_storage: CheckpointStorage,
}

/// Checkpoint storage options
#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum CheckpointStorage {
    Local,
    Distributed,
    Cloud,
    Custom(String),
}

/// Monitoring configuration
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct MonitoringConfiguration {
    pub enable_metrics: bool,
    pub enable_logging: bool,
    pub enable_tracing: bool,
    pub metrics_config: MetricsConfig,
    pub logging_config: LoggingConfig,
    pub alerting_config: AlertingConfig,
}

/// Metrics configuration
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct MetricsConfig {
    pub collection_interval: Duration,
    pub retention_period: Duration,
    pub custom_metrics: Vec<CustomMetric>,
}

/// Custom metric definition
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct CustomMetric {
    pub name: String,
    pub metric_type: MetricType,
    pub description: String,
    pub labels: Vec<String>,
}

/// Metric types
#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum MetricType {
    Counter,
    Gauge,
    Histogram,
    Summary,
}

/// Logging configuration
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct LoggingConfig {
    pub log_level: LogLevel,
    pub log_format: LogFormat,
    pub retention_days: u32,
    pub log_destinations: Vec<LogDestination>,
}

/// Log levels
#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum LogLevel {
    Error,
    Warn,
    Info,
    Debug,
    Trace,
}

/// Log formats
#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum LogFormat {
    Json,
    Text,
    Structured,
}

/// Log destinations
#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum LogDestination {
    Console,
    File(String),
    Network(String),
    Database(String),
}

/// Alerting configuration
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct AlertingConfig {
    pub enable_alerts: bool,
    pub alert_rules: Vec<AlertRule>,
    pub notification_channels: Vec<NotificationChannel>,
}

/// Alert rule definition
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct AlertRule {
    pub rule_id: String,
    pub condition: AlertCondition,
    pub severity: AlertSeverity,
    pub message: String,
    pub channels: Vec<String>,
}

/// Alert conditions
#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum AlertCondition {
    MetricThreshold { metric: String, threshold: f64, operator: ComparisonOperator },
    ErrorRate { threshold: f64, window: Duration },
    ResourceUsage { resource: String, threshold: f64 },
    Custom(String, serde_json::Value),
}

/// Comparison operators for alerts
#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum ComparisonOperator {
    GreaterThan,
    LessThan,
    Equal,
    NotEqual,
    GreaterThanOrEqual,
    LessThanOrEqual,
}

/// Alert severity levels
#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum AlertSeverity {
    Info,
    Warning,
    Error,
    Critical,
}

/// Notification channels
#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum NotificationChannel {
    Email { addresses: Vec<String> },
    Slack { webhook_url: String, channel: String },
    Webhook { url: String, headers: HashMap<String, String> },
    SMS { phone_numbers: Vec<String> },
}

/// Catalog-HyperMesh deployment bridge
pub struct CatalogHyperMeshBridge {
    /// VM runtime for code execution
    vm_runtime: Arc<ConsensusProofVM>,
    /// Container orchestrator
    container_orchestrator: Arc<HyperMeshContainerOrchestrator>,
    /// Active deployments tracking
    active_deployments: Arc<RwLock<HashMap<String, DeploymentInfo>>>,
    /// Bridge metrics
    metrics: Arc<Mutex<BridgeMetrics>>,
    /// Configuration
    config: BridgeConfiguration,
}

/// Deployment information tracking
#[derive(Debug, Clone)]
pub struct DeploymentInfo {
    pub deployment_id: String,
    pub asset_type: String,
    pub deployment_strategy: String,
    pub deployed_at: SystemTime,
    pub status: DeploymentStatus,
    pub resource_allocations: HashMap<AssetType, u64>,
    pub performance_metrics: PerformanceMetrics,
}

/// Deployment status
#[derive(Debug, Clone)]
pub enum DeploymentStatus {
    Pending,
    Deploying,
    Running,
    Scaling,
    Stopping,
    Stopped,
    Failed(String),
}

/// Performance metrics for deployments
#[derive(Debug, Clone, Default)]
pub struct PerformanceMetrics {
    pub execution_count: u64,
    pub average_execution_time: Duration,
    pub success_rate: f64,
    pub error_rate: f64,
    pub throughput: f64,
    pub latency_p95: Duration,
    pub resource_efficiency: f64,
}

/// Bridge metrics
#[derive(Debug, Default)]
pub struct BridgeMetrics {
    pub total_deployments: u64,
    pub vm_deployments: u64,
    pub container_deployments: u64,
    pub hybrid_deployments: u64,
    pub successful_deployments: u64,
    pub failed_deployments: u64,
    pub average_deployment_time: Duration,
    pub resource_utilization: f64,
}

/// Bridge configuration
#[derive(Debug, Clone)]
pub struct BridgeConfiguration {
    pub enable_vm_deployments: bool,
    pub enable_container_deployments: bool,
    pub enable_hybrid_deployments: bool,
    pub default_vm_config: VMDeploymentConfig,
    pub default_container_config: ContainerDeploymentConfig,
    pub max_concurrent_deployments: u32,
    pub deployment_timeout: Duration,
}

impl Default for BridgeConfiguration {
    fn default() -> Self {
        Self {
            enable_vm_deployments: true,
            enable_container_deployments: true,
            enable_hybrid_deployments: true,
            default_vm_config: VMDeploymentConfig {
                language_runtime: "julia".to_string(),
                execution_timeout: Duration::from_secs(300),
                memory_limit: 1024 * 1024 * 1024, // 1GB
                cpu_limit: 2,
                enable_gpu: false,
                environment_variables: HashMap::new(),
            },
            default_container_config: ContainerDeploymentConfig {
                base_image: "ubuntu:20.04".to_string(),
                ports: vec![],
                volumes: vec![],
                environment_variables: HashMap::new(),
                command: vec![],
                args: vec![],
            },
            max_concurrent_deployments: 50,
            deployment_timeout: Duration::from_secs(600),
        }
    }
}

impl CatalogHyperMeshBridge {
    /// Create new Catalog-HyperMesh bridge
    pub async fn new(
        vm_runtime: Arc<ConsensusProofVM>,
        container_orchestrator: Arc<HyperMeshContainerOrchestrator>,
        config: BridgeConfiguration,
    ) -> Result<Self> {
        Ok(Self {
            vm_runtime,
            container_orchestrator,
            active_deployments: Arc::new(RwLock::new(HashMap::new())),
            metrics: Arc::new(Mutex::new(BridgeMetrics::default())),
            config,
        })
    }
    
    /// Deploy catalog asset using specified strategy
    pub async fn deploy_catalog_asset(
        &self,
        deployment_spec: CatalogDeploymentSpec,
        consensus_proof: ConsensusProof,
    ) -> Result<CatalogDeploymentResult> {
        let deployment_id = Uuid::new_v4().to_string();
        let start_time = SystemTime::now();
        
        // Create deployment info
        let deployment_info = DeploymentInfo {
            deployment_id: deployment_id.clone(),
            asset_type: self.get_asset_type_name(&deployment_spec.asset),
            deployment_strategy: self.get_strategy_name(&deployment_spec.deployment_strategy),
            deployed_at: start_time,
            status: DeploymentStatus::Deploying,
            resource_allocations: HashMap::new(),
            performance_metrics: PerformanceMetrics::default(),
        };
        
        // Register deployment
        {
            let mut deployments = self.active_deployments.write().await;
            deployments.insert(deployment_id.clone(), deployment_info);
        }
        
        // Deploy based on strategy
        let deployment_result = match &deployment_spec.deployment_strategy {
            DeploymentStrategy::VMExecution { vm_config } => {
                self.deploy_as_vm(&deployment_spec.asset, vm_config, &consensus_proof).await?
            },
            DeploymentStrategy::Container { container_config } => {
                self.deploy_as_container(&deployment_spec.asset, container_config, &consensus_proof).await?
            },
            DeploymentStrategy::Serverless { function_config } => {
                self.deploy_as_function(&deployment_spec.asset, function_config, &consensus_proof).await?
            },
            DeploymentStrategy::Hybrid { vm_config, container_config } => {
                self.deploy_as_hybrid(&deployment_spec.asset, vm_config, container_config, &consensus_proof).await?
            },
        };
        
        // Update deployment status
        {
            let mut deployments = self.active_deployments.write().await;
            if let Some(deployment) = deployments.get_mut(&deployment_id) {
                deployment.status = if deployment_result.success {
                    DeploymentStatus::Running
                } else {
                    DeploymentStatus::Failed(deployment_result.error_message.clone().unwrap_or_default())
                };
            }
        }
        
        // Update metrics
        {
            let mut metrics = self.metrics.lock().await;
            metrics.total_deployments += 1;
            
            match deployment_spec.deployment_strategy {
                DeploymentStrategy::VMExecution { .. } => metrics.vm_deployments += 1,
                DeploymentStrategy::Container { .. } => metrics.container_deployments += 1,
                DeploymentStrategy::Hybrid { .. } => metrics.hybrid_deployments += 1,
                _ => {},
            }
            
            if deployment_result.success {
                metrics.successful_deployments += 1;
            } else {
                metrics.failed_deployments += 1;
            }
            
            let deployment_time = start_time.elapsed().unwrap_or_default();
            let total_time = metrics.average_deployment_time.as_micros() as u64 * (metrics.total_deployments - 1)
                + deployment_time.as_micros() as u64;
            metrics.average_deployment_time = Duration::from_micros(total_time / metrics.total_deployments);
        }
        
        Ok(CatalogDeploymentResult {
            deployment_id,
            success: deployment_result.success,
            output: deployment_result.output,
            error_message: deployment_result.error_message,
            deployment_time: start_time.elapsed().unwrap_or_default(),
            resource_allocations: deployment_result.resource_allocations,
            performance_metrics: PerformanceMetrics::default(),
        })
    }
    
    /// Deploy asset as VM execution
    async fn deploy_as_vm(
        &self,
        asset: &CatalogAssetType,
        vm_config: &VMDeploymentConfig,
        consensus_proof: &ConsensusProof,
    ) -> Result<InternalDeploymentResult> {
        match asset {
            CatalogAssetType::JuliaScript { code, .. } => {
                let execution_context = ExecutionContext::new(
                    "julia".to_string(),
                    consensus_proof.clone(),
                    HashMap::new(), // Asset allocations would be populated
                );
                
                let result = self.vm_runtime.execute_with_consensus(
                    code,
                    "julia",
                    consensus_proof.clone(),
                ).await?;
                
                Ok(InternalDeploymentResult {
                    success: result.success,
                    output: result.output,
                    error_message: result.error_message,
                    resource_allocations: HashMap::new(), // Would be populated from result
                })
            },
            CatalogAssetType::PythonApp { code, .. } => {
                let result = self.vm_runtime.execute_with_consensus(
                    code,
                    "python",
                    consensus_proof.clone(),
                ).await?;
                
                Ok(InternalDeploymentResult {
                    success: result.success,
                    output: result.output,
                    error_message: result.error_message,
                    resource_allocations: HashMap::new(),
                })
            },
            CatalogAssetType::RustBinary { source_code, .. } => {
                let result = self.vm_runtime.execute_with_consensus(
                    source_code,
                    "rust",
                    consensus_proof.clone(),
                ).await?;
                
                Ok(InternalDeploymentResult {
                    success: result.success,
                    output: result.output,
                    error_message: result.error_message,
                    resource_allocations: HashMap::new(),
                })
            },
            _ => Err(anyhow!("Asset type not supported for VM deployment")),
        }
    }
    
    /// Deploy asset as container
    async fn deploy_as_container(
        &self,
        asset: &CatalogAssetType,
        container_config: &ContainerDeploymentConfig,
        consensus_proof: &ConsensusProof,
    ) -> Result<InternalDeploymentResult> {
        match asset {
            CatalogAssetType::ContainerImage { image_name, image_tag, .. } => {
                let container_spec = ContainerSpec {
                    image: format!("{}:{}", image_name, image_tag),
                    command: container_config.command.clone(),
                    args: container_config.args.clone(),
                    environment: container_config.environment_variables.clone(),
                    resources: ResourceRequirements::default(),
                    network: Default::default(),
                };
                
                let hypermesh_spec = HyperMeshContainerSpec {
                    container_spec,
                    required_assets: HashMap::new(), // Would be calculated based on resource requirements
                    consensus_proof: consensus_proof.clone(),
                    privacy_requirements: PrivacyRequirements::default(),
                    performance_requirements: PerformanceRequirements::default(),
                    metadata: ContainerMetadata {
                        deployment_id: Uuid::new_v4().to_string(),
                        application_name: image_name.clone(),
                        version: image_tag.clone(),
                        owner: "catalog-bridge".to_string(),
                        tags: HashMap::new(),
                        deployed_at: SystemTime::now(),
                    },
                };
                
                let deployment_result = self.container_orchestrator.deploy_container(hypermesh_spec).await?;
                
                Ok(InternalDeploymentResult {
                    success: true,
                    output: Some(serde_json::json!({
                        "container_id": deployment_result.container_handle.id.to_string(),
                        "status": "running"
                    })),
                    error_message: None,
                    resource_allocations: deployment_result.allocated_assets.keys()
                        .map(|asset_type| (asset_type.clone(), 1))
                        .collect(),
                })
            },
            _ => Err(anyhow!("Asset type not supported for container deployment")),
        }
    }
    
    /// Deploy asset as serverless function
    async fn deploy_as_function(
        &self,
        asset: &CatalogAssetType,
        function_config: &FunctionDeploymentConfig,
        consensus_proof: &ConsensusProof,
    ) -> Result<InternalDeploymentResult> {
        // Serverless deployment would be implemented here
        // For now, delegate to VM execution with timeout
        let vm_config = VMDeploymentConfig {
            language_runtime: function_config.runtime.clone(),
            execution_timeout: function_config.timeout,
            memory_limit: function_config.memory_size,
            cpu_limit: 1,
            enable_gpu: false,
            environment_variables: HashMap::new(),
        };
        
        self.deploy_as_vm(asset, &vm_config, consensus_proof).await
    }
    
    /// Deploy asset as hybrid (VM + Container)
    async fn deploy_as_hybrid(
        &self,
        asset: &CatalogAssetType,
        vm_config: &VMDeploymentConfig,
        container_config: &ContainerDeploymentConfig,
        consensus_proof: &ConsensusProof,
    ) -> Result<InternalDeploymentResult> {
        // Deploy both VM and container components
        let vm_result = self.deploy_as_vm(asset, vm_config, consensus_proof).await?;
        let container_result = self.deploy_as_container(asset, container_config, consensus_proof).await?;
        
        let success = vm_result.success && container_result.success;
        let combined_output = serde_json::json!({
            "vm_result": vm_result.output,
            "container_result": container_result.output
        });
        
        Ok(InternalDeploymentResult {
            success,
            output: Some(combined_output),
            error_message: if success { None } else { 
                Some(format!("VM: {:?}, Container: {:?}", vm_result.error_message, container_result.error_message))
            },
            resource_allocations: {
                let mut allocations = vm_result.resource_allocations;
                allocations.extend(container_result.resource_allocations);
                allocations
            },
        })
    }
    
    /// Get asset type name for tracking
    fn get_asset_type_name(&self, asset: &CatalogAssetType) -> String {
        match asset {
            CatalogAssetType::JuliaScript { .. } => "julia_script".to_string(),
            CatalogAssetType::PythonApp { .. } => "python_app".to_string(),
            CatalogAssetType::RustBinary { .. } => "rust_binary".to_string(),
            CatalogAssetType::ContainerImage { .. } => "container_image".to_string(),
            CatalogAssetType::WasmModule { .. } => "wasm_module".to_string(),
            CatalogAssetType::DataPipeline { .. } => "data_pipeline".to_string(),
        }
    }
    
    /// Get deployment strategy name for tracking
    fn get_strategy_name(&self, strategy: &DeploymentStrategy) -> String {
        match strategy {
            DeploymentStrategy::VMExecution { .. } => "vm_execution".to_string(),
            DeploymentStrategy::Container { .. } => "container".to_string(),
            DeploymentStrategy::Serverless { .. } => "serverless".to_string(),
            DeploymentStrategy::Hybrid { .. } => "hybrid".to_string(),
        }
    }
    
    /// Get bridge metrics
    pub async fn get_metrics(&self) -> BridgeMetrics {
        let metrics = self.metrics.lock().await;
        metrics.clone()
    }
    
    /// List active deployments
    pub async fn list_deployments(&self) -> Vec<DeploymentInfo> {
        let deployments = self.active_deployments.read().await;
        deployments.values().cloned().collect()
    }
    
    /// Stop deployment
    pub async fn stop_deployment(&self, deployment_id: &str) -> Result<()> {
        // Implementation would stop VM executions or container deployments
        // For now, just update status
        let mut deployments = self.active_deployments.write().await;
        if let Some(deployment) = deployments.get_mut(deployment_id) {
            deployment.status = DeploymentStatus::Stopped;
        }
        Ok(())
    }
}

/// Internal deployment result
#[derive(Debug)]
struct InternalDeploymentResult {
    pub success: bool,
    pub output: Option<serde_json::Value>,
    pub error_message: Option<String>,
    pub resource_allocations: HashMap<AssetType, u64>,
}

/// Catalog deployment result
#[derive(Debug, Clone)]
pub struct CatalogDeploymentResult {
    pub deployment_id: String,
    pub success: bool,
    pub output: Option<serde_json::Value>,
    pub error_message: Option<String>,
    pub deployment_time: Duration,
    pub resource_allocations: HashMap<AssetType, u64>,
    pub performance_metrics: PerformanceMetrics,
}

impl Clone for BridgeMetrics {
    fn clone(&self) -> Self {
        Self {
            total_deployments: self.total_deployments,
            vm_deployments: self.vm_deployments,
            container_deployments: self.container_deployments,
            hybrid_deployments: self.hybrid_deployments,
            successful_deployments: self.successful_deployments,
            failed_deployments: self.failed_deployments,
            average_deployment_time: self.average_deployment_time,
            resource_utilization: self.resource_utilization,
        }
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    
    #[test]
    fn test_catalog_asset_types() {
        let julia_script = CatalogAssetType::JuliaScript {
            code: "println(\"Hello, World!\")".to_string(),
            dependencies: vec!["DataFrames".to_string()],
            entry_point: "main".to_string(),
        };
        
        assert!(matches!(julia_script, CatalogAssetType::JuliaScript { .. }));
    }
    
    #[test]
    fn test_deployment_strategies() {
        let vm_config = VMDeploymentConfig {
            language_runtime: "julia".to_string(),
            execution_timeout: Duration::from_secs(300),
            memory_limit: 1024 * 1024 * 1024,
            cpu_limit: 2,
            enable_gpu: false,
            environment_variables: HashMap::new(),
        };
        
        let strategy = DeploymentStrategy::VMExecution { vm_config };
        assert!(matches!(strategy, DeploymentStrategy::VMExecution { .. }));
    }
    
    #[tokio::test]
    async fn test_bridge_creation() {
        // This test would require actual VM and container orchestrator instances
        // For now, we just test the configuration
        let config = BridgeConfiguration::default();
        assert!(config.enable_vm_deployments);
        assert!(config.enable_container_deployments);
        assert_eq!(config.max_concurrent_deployments, 50);
    }
}