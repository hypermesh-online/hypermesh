//! GPU Asset Adapter with Nova engine and Vulkan compute management
//!
//! Features:
//! - Nova engine GPU compute unit allocation (Vulkan compute shaders)
//! - Vulkan-based memory management (device memory, buffers)
//! - Multi-GPU coordination and scheduling via Nova
//! - Hardware acceleration for consensus proofs
//! - Quantum-resistant security with FALCON-1024
//! - Remote proxy access for distributed GPU compute

use std::collections::HashMap;
use std::sync::Arc;
use std::time::{Duration, SystemTime};
use async_trait::async_trait;
use tokio::sync::RwLock;
use serde::{Deserialize, Serialize};

use crate::assets::core::{
    AssetAdapter, AssetId, AssetType, AssetResult, AssetError,
    AssetAllocationRequest, AssetStatus, AssetState,
    PrivacyLevel, AssetAllocation, ProxyAddress,
    ResourceUsage, ResourceLimits, GpuUsage, GpuLimit,
    AdapterHealth, AdapterCapabilities, ConsensusProof,
    GpuRequirements,
};

/// GPU allocation record
#[derive(Clone, Debug, Serialize, Deserialize)]
pub struct GpuAllocation {
    /// Asset ID
    pub asset_id: AssetId,
    /// Allocated GPU device IDs
    pub allocated_devices: Vec<u32>,
    /// GPU memory allocated in bytes
    pub allocated_memory_bytes: u64,
    /// Compute capability required
    pub compute_capability: String,
    /// Nova engine features enabled (Vulkan compute, Ray tracing, etc.)
    pub enabled_features: Vec<String>,
    /// Privacy level
    pub privacy_level: PrivacyLevel,
    /// Process isolation enabled
    pub isolation_enabled: bool,
    /// GPU compute priority (0-255)
    pub compute_priority: u8,
    /// Allocation timestamp
    pub allocated_at: SystemTime,
    /// Last accessed timestamp
    pub last_accessed: SystemTime,
    /// Current GPU utilization percentage
    pub current_utilization: f32,
    /// Current memory utilization percentage
    pub memory_utilization: f32,
    /// GPU context handle
    pub context_handle: Option<String>,
}

/// GPU device information
#[derive(Clone, Debug, Serialize, Deserialize)]
pub struct GpuDevice {
    /// Device ID
    pub device_id: u32,
    /// Device name
    pub device_name: String,
    /// Compute capability (e.g., "8.6" for RTX 30xx)
    pub compute_capability: String,
    /// Total memory in bytes
    pub total_memory_bytes: u64,
    /// Available memory in bytes
    pub available_memory_bytes: u64,
    /// Vulkan compute units
    pub vulkan_compute_units: u32,
    /// Nova execution units
    pub nova_execution_units: u32,
    /// Base clock in MHz
    pub base_clock_mhz: u32,
    /// Memory clock in MHz
    pub memory_clock_mhz: u32,
    /// PCI bus ID
    pub pci_bus_id: String,
    /// Current status
    pub status: GpuStatus,
    /// Current allocation asset ID
    pub allocated_to: Option<AssetId>,
    /// Temperature in Celsius
    pub temperature_celsius: Option<f32>,
    /// Power consumption in watts
    pub power_watts: Option<f32>,
}

/// GPU device status
#[derive(Clone, Debug, Serialize, Deserialize)]
pub enum GpuStatus {
    /// GPU is available for allocation
    Available,
    /// GPU is allocated but idle
    Allocated,
    /// GPU is actively computing
    Computing,
    /// GPU is in maintenance mode
    Maintenance,
    /// GPU has failed
    Failed,
}

/// GPU compute context for isolation
#[derive(Clone, Debug)]
pub struct GpuContext {
    /// Context ID
    pub context_id: String,
    /// Associated asset ID
    pub asset_id: AssetId,
    /// Device ID
    pub device_id: u32,
    /// Memory allocated to context
    pub allocated_memory: u64,
    /// Compute streams
    pub compute_streams: Vec<u32>,
    /// Created timestamp
    pub created_at: SystemTime,
    /// Last activity timestamp
    pub last_activity: SystemTime,
}

/// GPU Asset Adapter implementation
pub struct GpuAssetAdapter {
    /// Active GPU allocations by asset ID
    allocations: Arc<RwLock<HashMap<AssetId, GpuAllocation>>>,
    /// GPU device information and status
    gpu_devices: Arc<RwLock<HashMap<u32, GpuDevice>>>,
    /// Device allocation mapping (device_id -> asset_id)
    device_allocations: Arc<RwLock<HashMap<u32, AssetId>>>,
    /// GPU compute contexts
    gpu_contexts: Arc<RwLock<HashMap<String, GpuContext>>>,
    /// Proxy address mappings
    proxy_mappings: Arc<RwLock<HashMap<ProxyAddress, AssetId>>>,
    /// Total GPU devices available
    total_devices: u32,
    /// GPU usage statistics
    usage_stats: Arc<RwLock<GpuUsageStats>>,
}

/// GPU usage statistics
#[derive(Clone, Debug, Default)]
pub struct GpuUsageStats {
    /// Total allocations made
    pub total_allocations: u64,
    /// Total deallocations made
    pub total_deallocations: u64,
    /// Current active allocations
    pub active_allocations: u64,
    /// Total GPU memory allocated (bytes)
    pub total_memory_allocated: u64,
    /// Average GPU utilization
    pub average_utilization: f32,
    /// Peak GPU utilization
    pub peak_utilization: f32,
    /// Compute operations performed
    pub compute_operations: u64,
    /// Memory transfers performed
    pub memory_transfers: u64,
}

impl GpuAssetAdapter {
    /// Create new GPU adapter
    pub async fn new() -> Self {
        // Detect system GPU configuration
        let (total_devices, gpu_devices) = Self::detect_gpu_configuration().await;
        
        Self {
            allocations: Arc::new(RwLock::new(HashMap::new())),
            gpu_devices: Arc::new(RwLock::new(gpu_devices)),
            device_allocations: Arc::new(RwLock::new(HashMap::new())),
            gpu_contexts: Arc::new(RwLock::new(HashMap::new())),
            proxy_mappings: Arc::new(RwLock::new(HashMap::new())),
            total_devices,
            usage_stats: Arc::new(RwLock::new(GpuUsageStats::default())),
        }
    }
    
    /// Detect system GPU configuration
    async fn detect_gpu_configuration() -> (u32, HashMap<u32, GpuDevice>) {
        // TODO: Implement actual GPU detection using Nova engine and Vulkan APIs
        // For now, simulate a reasonable configuration
        let total_devices = 2; // Assume 2 GPUs
        let mut gpu_devices = HashMap::new();
        
        for device_id in 0..total_devices {
            gpu_devices.insert(device_id, GpuDevice {
                device_id,
                device_name: format!("NVIDIA RTX 4080 #{}", device_id),
                compute_capability: "8.9".to_string(),
                total_memory_bytes: 16 * 1024 * 1024 * 1024, // 16GB VRAM
                available_memory_bytes: 16 * 1024 * 1024 * 1024,
                vulkan_compute_units: 9728,
                nova_execution_units: 76,
                base_clock_mhz: 2205,
                memory_clock_mhz: 11400,
                pci_bus_id: format!("0000:0{}:00.0", device_id + 1),
                status: GpuStatus::Available,
                allocated_to: None,
                temperature_celsius: Some(35.0 + (device_id as f32 * 5.0)),
                power_watts: Some(220.0),
            });
        }
        
        (total_devices, gpu_devices)
    }
    
    /// Allocate GPU devices based on requirements
    async fn allocate_gpu_devices(
        &self,
        gpu_req: &GpuRequirements,
        asset_id: &AssetId,
    ) -> AssetResult<(Vec<u32>, u64)> {
        let mut devices = self.gpu_devices.write().await;
        let mut device_allocations = self.device_allocations.write().await;
        let mut allocated_devices = Vec::new();
        let mut total_allocated_memory = 0u64;
        
        // Find available devices matching requirements
        let mut available_devices: Vec<u32> = devices
            .iter()
            .filter(|(_, device)| {
                matches!(device.status, GpuStatus::Available) &&
                device.available_memory_bytes >= gpu_req.min_memory_mb.unwrap_or(0) as u64 * 1024 * 1024 &&
                (gpu_req.compute_capability.is_none() || 
                 device.compute_capability >= *gpu_req.compute_capability.as_ref().unwrap())
            })
            .map(|(device_id, _)| *device_id)
            .collect();
        
        // Sort by available memory (largest first)
        available_devices.sort_by_key(|device_id| {
            let device = devices.get(device_id).unwrap();
            std::cmp::Reverse(device.available_memory_bytes)
        });
        
        // Check if we have enough devices
        if available_devices.len() < gpu_req.units as usize {
            return Err(AssetError::AllocationFailed {
                reason: format!(
                    "Insufficient GPU devices: {} requested, {} available",
                    gpu_req.units, available_devices.len()
                )
            });
        }
        
        // Allocate the requested number of devices
        let memory_per_device = gpu_req.min_memory_mb.unwrap_or(1024) as u64 * 1024 * 1024;
        
        for &device_id in available_devices.iter().take(gpu_req.units as usize) {
            let device = devices.get_mut(&device_id).unwrap();
            
            // Check if device has enough memory
            if device.available_memory_bytes < memory_per_device {
                continue; // Skip this device
            }
            
            device.status = GpuStatus::Allocated;
            device.allocated_to = Some(asset_id.clone());
            device.available_memory_bytes -= memory_per_device;
            
            device_allocations.insert(device_id, asset_id.clone());
            allocated_devices.push(device_id);
            total_allocated_memory += memory_per_device;
        }
        
        if allocated_devices.len() < gpu_req.units as usize {
            // Rollback partial allocation
            for &device_id in &allocated_devices {
                let device = devices.get_mut(&device_id).unwrap();
                device.status = GpuStatus::Available;
                device.allocated_to = None;
                device.available_memory_bytes += memory_per_device;
                device_allocations.remove(&device_id);
            }
            
            return Err(AssetError::AllocationFailed {
                reason: "Insufficient GPU memory across available devices".to_string()
            });
        }
        
        Ok((allocated_devices, total_allocated_memory))
    }
    
    /// Generate proxy address for GPU access
    async fn generate_proxy_address(asset_id: &AssetId) -> ProxyAddress {
        let uuid_bytes = asset_id.uuid.as_bytes();
        let mut node_id = [0u8; 8];
        node_id.copy_from_slice(&uuid_bytes[..8]);
        ProxyAddress::new(
            [0x2a, 0x01, 0x04, 0xf8, 0x01, 0x10, 0x53, 0xad,
             0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x01],
            node_id,
            8080
        )
    }
    
    /// Create GPU compute context for isolation
    async fn create_gpu_context(&self, asset_id: &AssetId, device_id: u32) -> String {
        let context_id = format!("gpu_ctx_{}_{}", device_id, asset_id.uuid);
        
        let context = GpuContext {
            context_id: context_id.clone(),
            asset_id: asset_id.clone(),
            device_id,
            allocated_memory: 0, // Will be updated when memory is allocated
            compute_streams: vec![0, 1], // Default streams
            created_at: SystemTime::now(),
            last_activity: SystemTime::now(),
        };
        
        let mut contexts = self.gpu_contexts.write().await;
        contexts.insert(context_id.clone(), context);
        
        context_id
    }
    
    /// Accelerate consensus proof validation using GPU
    async fn accelerate_consensus_validation(&self, proof: &ConsensusProof) -> AssetResult<bool> {
        // TODO: Implement GPU-accelerated consensus proof validation
        // This could include:
        // - Parallel hash computation for PoSpace
        // - Cryptographic operations for PoStake
        // - Accelerated work validation for PoWork
        // - Time synchronization calculations for PoTime
        
        // For now, use standard validation but could be accelerated
        proof.validate().await
    }
    
    /// Update usage statistics
    async fn update_usage_stats(&self, operation: GpuOperation, devices: u32, memory_bytes: u64) {
        let mut stats = self.usage_stats.write().await;
        
        match operation {
            GpuOperation::Allocate => {
                stats.total_allocations += 1;
                stats.active_allocations += 1;
                stats.total_memory_allocated += memory_bytes;
            },
            GpuOperation::Deallocate => {
                stats.total_deallocations += 1;
                stats.active_allocations = stats.active_allocations.saturating_sub(1);
                stats.total_memory_allocated = stats.total_memory_allocated.saturating_sub(memory_bytes);
            },
            GpuOperation::Compute => {
                stats.compute_operations += 1;
            },
            GpuOperation::MemoryTransfer => {
                stats.memory_transfers += 1;
            },
        }
    }
}

/// GPU operations for statistics
#[derive(Clone, Debug)]
enum GpuOperation {
    Allocate,
    Deallocate,
    Compute,
    MemoryTransfer,
}

#[async_trait]
impl AssetAdapter for GpuAssetAdapter {
    fn asset_type(&self) -> AssetType {
        AssetType::Gpu
    }
    
    async fn validate_consensus_proof(&self, proof: &ConsensusProof) -> AssetResult<bool> {
        // Use GPU acceleration for consensus validation if available
        if self.total_devices > 0 {
            return self.accelerate_consensus_validation(proof).await;
        }
        
        // Fallback to standard validation with GPU-specific requirements
        let valid = proof.validate().await?;
        
        if !valid {
            return Ok(false);
        }
        
        // GPU-specific validation
        // PoSpace: Validate GPU memory space allocation
        if proof.proof_of_space.committed_space == 0 {
            return Ok(false);
        }
        
        // PoStake: Validate GPU access stake (higher requirement for GPU resources)
        if proof.proof_of_stake.stake_amount < 200 { // Higher minimum for GPU
            return Ok(false);
        }
        
        // PoWork: Validate computational work (GPU provides high compute power)
        if proof.proof_of_work.difficulty < 20 { // Higher difficulty for GPU
            return Ok(false);
        }
        
        // PoTime: Validate temporal constraints (GPUs need tight synchronization)
        let time_valid = proof.proof_of_time.logical_timestamp > 0 &&
                        proof.proof_of_time.sequence_number > 0;
        
        Ok(time_valid)
    }
    
    async fn allocate_asset(&self, request: &AssetAllocationRequest) -> AssetResult<AssetAllocation> {
        // Validate consensus proof first (with GPU acceleration if available)
        if !self.validate_consensus_proof(&request.consensus_proof).await? {
            return Err(AssetError::ConsensusValidationFailed {
                reason: "GPU allocation consensus validation failed".to_string()
            });
        }
        
        // Get GPU requirements
        let gpu_req = request.requested_resources.gpu.as_ref()
            .ok_or_else(|| AssetError::AllocationFailed {
                reason: "No GPU requirements specified".to_string()
            })?;
        
        // Create asset ID
        let asset_id = AssetId::new(AssetType::Gpu);
        
        // Allocate GPU devices and memory
        let (allocated_devices, allocated_memory) = self.allocate_gpu_devices(gpu_req, &asset_id).await?;
        
        // Generate proxy address
        let proxy_address = Self::generate_proxy_address(&asset_id).await;
        
        // Create GPU contexts for isolation
        let mut context_handles = Vec::new();
        for &device_id in &allocated_devices {
            let context_id = self.create_gpu_context(&asset_id, device_id).await;
            context_handles.push(context_id);
        }
        
        // Create GPU allocation record
        let allocation = GpuAllocation {
            asset_id: asset_id.clone(),
            allocated_devices: allocated_devices.clone(),
            allocated_memory_bytes: allocated_memory,
            compute_capability: gpu_req.compute_capability.clone().unwrap_or_else(|| "8.0".to_string()),
            enabled_features: gpu_req.required_features.clone(),
            privacy_level: request.privacy_level.clone(),
            isolation_enabled: true, // Enable isolation by default
            compute_priority: 128, // Default priority
            allocated_at: SystemTime::now(),
            last_accessed: SystemTime::now(),
            current_utilization: 0.0,
            memory_utilization: 0.0,
            context_handle: context_handles.first().cloned(),
        };
        
        // Store allocation and proxy mapping
        {
            let mut allocations = self.allocations.write().await;
            allocations.insert(asset_id.clone(), allocation);
        }
        
        {
            let mut proxy_mappings = self.proxy_mappings.write().await;
            proxy_mappings.insert(proxy_address.clone(), asset_id.clone());
        }
        
        // Update usage statistics
        self.update_usage_stats(GpuOperation::Allocate, gpu_req.units, allocated_memory).await;
        
        Ok(AssetAllocation {
            asset_id: asset_id.clone(),
            status: AssetStatus {
                asset_id: asset_id.clone(),
                state: AssetState::Allocated,
                allocated_at: SystemTime::now(),
                last_accessed: SystemTime::now(),
                resource_usage: ResourceUsage {
                    cpu_usage: None,
                    gpu_usage: None,
                    memory_usage: None,
                    storage_usage: None,
                    network_usage: None,
                    measurement_timestamp: SystemTime::now(),
                },
                privacy_level: PrivacyLevel::Private,
                proxy_address: None,
                consensus_proofs: Vec::new(),
                owner_certificate_fingerprint: request.certificate_fingerprint.clone(),
                metadata: HashMap::new(),
                health_status: crate::assets::core::status::AssetHealthStatus::default(),
                performance_metrics: crate::assets::core::status::AssetPerformanceMetrics::default(),
            },
            allocation_config: crate::assets::core::privacy::AllocationConfig {
                privacy_level: request.privacy_level.clone(),
                resource_allocation: crate::assets::core::privacy::ResourceAllocationConfig::default(),
                concurrency_limits: crate::assets::core::privacy::ConcurrencyLimits::default(),
                duration_config: crate::assets::core::privacy::DurationConfig::default(),
                consensus_requirements: crate::assets::core::privacy::ConsensusRequirements::default(),
            },
            access_config: crate::assets::core::privacy::AccessConfig {
                allowed_certificates: vec![request.certificate_fingerprint.clone()],
                allowed_networks: Vec::new(),
                permissions: crate::assets::core::privacy::AccessPermissions::default(),
                rate_limits: crate::assets::core::privacy::RateLimits::default(),
                auth_requirements: crate::assets::core::privacy::AuthRequirements::default(),
            },
            allocated_at: SystemTime::now(),
            expires_at: request.duration_limit.map(|d| SystemTime::now() + d),
        })
    }
    
    async fn deallocate_asset(&self, asset_id: &AssetId) -> AssetResult<()> {
        // Get allocation record
        let allocation = {
            let mut allocations = self.allocations.write().await;
            allocations.remove(asset_id)
                .ok_or_else(|| AssetError::AssetNotFound {
                    asset_id: asset_id.to_string()
                })?
        };
        
        // Free GPU devices and memory
        {
            let mut devices = self.gpu_devices.write().await;
            let mut device_allocations = self.device_allocations.write().await;
            
            let memory_per_device = allocation.allocated_memory_bytes / allocation.allocated_devices.len() as u64;
            
            for device_id in &allocation.allocated_devices {
                if let Some(device) = devices.get_mut(device_id) {
                    device.status = GpuStatus::Available;
                    device.allocated_to = None;
                    device.available_memory_bytes += memory_per_device;
                }
                device_allocations.remove(device_id);
            }
        }
        
        // Clean up GPU contexts
        {
            let mut contexts = self.gpu_contexts.write().await;
            contexts.retain(|_, context| context.asset_id != *asset_id);
        }
        
        // Remove proxy mapping
        {
            let mut proxy_mappings = self.proxy_mappings.write().await;
            proxy_mappings.retain(|_, mapped_asset_id| mapped_asset_id != asset_id);
        }
        
        // Update usage statistics
        self.update_usage_stats(
            GpuOperation::Deallocate, 
            allocation.allocated_devices.len() as u32, 
            allocation.allocated_memory_bytes
        ).await;
        
        tracing::info!(
            "Deallocated GPU asset: {} ({} devices, {} MB memory)", 
            asset_id, 
            allocation.allocated_devices.len(),
            allocation.allocated_memory_bytes / (1024 * 1024)
        );
        Ok(())
    }
    
    async fn get_asset_status(&self, asset_id: &AssetId) -> AssetResult<AssetStatus> {
        let allocations = self.allocations.read().await;
        let allocation = allocations.get(asset_id)
            .ok_or_else(|| AssetError::AssetNotFound {
                asset_id: asset_id.to_string()
            })?;
        
        Ok(AssetStatus {
            asset_id: asset_id.clone(),
            state: AssetState::InUse,
            allocated_at: allocation.allocated_at,
            last_accessed: allocation.last_accessed,
            privacy_level: allocation.privacy_level.clone(),
            proxy_address: None, // Will be filled by proxy resolver
            resource_usage: self.get_resource_usage(asset_id).await?,
            consensus_proofs: Vec::new(),
            owner_certificate_fingerprint: "gpu-adapter".to_string(),
            health_status: crate::assets::core::status::AssetHealthStatus::default(),
            performance_metrics: crate::assets::core::status::AssetPerformanceMetrics::default(),
            metadata: {
                let mut metadata = HashMap::new();
                metadata.insert("devices".to_string(), allocation.allocated_devices.len().to_string());
                metadata.insert("allocated_devices".to_string(), format!("{:?}", allocation.allocated_devices));
                metadata.insert("memory_bytes".to_string(), allocation.allocated_memory_bytes.to_string());
                metadata.insert("compute_capability".to_string(), allocation.compute_capability.clone());
                metadata.insert("utilization_percent".to_string(), allocation.current_utilization.to_string());
                metadata.insert("memory_utilization_percent".to_string(), allocation.memory_utilization.to_string());
                metadata.insert("isolation_enabled".to_string(), allocation.isolation_enabled.to_string());
                metadata
            },
        })
    }
    
    async fn configure_privacy_level(&self, asset_id: &AssetId, privacy: PrivacyLevel) -> AssetResult<()> {
        let mut allocations = self.allocations.write().await;
        let allocation = allocations.get_mut(asset_id)
            .ok_or_else(|| AssetError::AssetNotFound {
                asset_id: asset_id.to_string()
            })?;
        
        allocation.privacy_level = privacy.clone();
        
        tracing::info!("Updated privacy level for GPU asset {}: {:?}", asset_id, privacy);
        Ok(())
    }
    
    async fn assign_proxy_address(&self, asset_id: &AssetId) -> AssetResult<ProxyAddress> {
        let proxy_address = Self::generate_proxy_address(asset_id).await;
        
        // Find existing proxy address or create new one
        let proxy_mappings = self.proxy_mappings.read().await;
        for (proxy_addr, mapped_asset_id) in proxy_mappings.iter() {
            if mapped_asset_id == asset_id {
                return Ok(proxy_addr.clone());
            }
        }
        
        Ok(proxy_address)
    }
    
    async fn resolve_proxy_address(&self, proxy_addr: &ProxyAddress) -> AssetResult<AssetId> {
        let proxy_mappings = self.proxy_mappings.read().await;
        proxy_mappings.get(proxy_addr)
            .cloned()
            .ok_or_else(|| AssetError::ProxyResolutionFailed {
                address: proxy_addr.clone()
            })
    }
    
    async fn get_resource_usage(&self, asset_id: &AssetId) -> AssetResult<ResourceUsage> {
        let allocations = self.allocations.read().await;
        let allocation = allocations.get(asset_id)
            .ok_or_else(|| AssetError::AssetNotFound {
                asset_id: asset_id.to_string()
            })?;
        
        // TODO: Implement actual GPU usage monitoring
        let gpu_usage = GpuUsage {
            utilization_percent: allocation.current_utilization,
            memory_utilization_percent: allocation.memory_utilization,
            temperature_celsius: Some(65.0), // TODO: Get actual temperature
            power_watts: Some(200.0), // TODO: Get actual power consumption
        };
        
        Ok(ResourceUsage {
            cpu_usage: None,
            gpu_usage: Some(gpu_usage),
            memory_usage: None,
            storage_usage: None,
            network_usage: None,
            measurement_timestamp: SystemTime::now(),
        })
    }
    
    async fn set_resource_limits(&self, asset_id: &AssetId, limits: ResourceLimits) -> AssetResult<()> {
        if let Some(gpu_limit) = limits.gpu_limit {
            tracing::info!(
                "Set GPU limits for asset {}: max devices {}, max memory {} MB, max utilization {}%",
                asset_id,
                gpu_limit.max_units,
                gpu_limit.max_memory_bytes / (1024 * 1024),
                gpu_limit.max_utilization_percent
            );
        }
        Ok(())
    }
    
    async fn health_check(&self) -> AssetResult<AdapterHealth> {
        let stats = self.usage_stats.read().await;
        let devices = self.gpu_devices.read().await;
        
        let available_devices = devices.values().filter(|device| matches!(device.status, GpuStatus::Available)).count();
        let healthy = available_devices > 0 && stats.active_allocations < self.total_devices as u64;
        
        let total_memory = devices.values().map(|d| d.total_memory_bytes).sum::<u64>();
        let available_memory = devices.values().map(|d| d.available_memory_bytes).sum::<u64>();
        
        let mut performance_metrics = HashMap::new();
        performance_metrics.insert("total_devices".to_string(), self.total_devices as f64);
        performance_metrics.insert("available_devices".to_string(), available_devices as f64);
        performance_metrics.insert("total_memory_gb".to_string(), (total_memory / (1024 * 1024 * 1024)) as f64);
        performance_metrics.insert("available_memory_gb".to_string(), (available_memory / (1024 * 1024 * 1024)) as f64);
        performance_metrics.insert("memory_utilization_percent".to_string(), 
            ((total_memory - available_memory) as f64 / total_memory as f64) * 100.0);
        performance_metrics.insert("active_allocations".to_string(), stats.active_allocations as f64);
        performance_metrics.insert("compute_operations".to_string(), stats.compute_operations as f64);
        
        Ok(AdapterHealth {
            healthy,
            message: if healthy {
                "GPU adapter operating normally".to_string()
            } else {
                "GPU adapter experiencing issues".to_string()
            },
            last_check: SystemTime::now(),
            performance_metrics,
        })
    }
    
    fn get_capabilities(&self) -> AdapterCapabilities {
        AdapterCapabilities {
            asset_type: AssetType::Gpu,
            supported_privacy_levels: vec![
                PrivacyLevel::Private,
                PrivacyLevel::PrivateNetwork,
                PrivacyLevel::P2P,
                PrivacyLevel::PublicNetwork,
                PrivacyLevel::FullPublic,
            ],
            supports_proxy_addressing: true,
            supports_resource_monitoring: true,
            supports_dynamic_limits: true,
            max_concurrent_allocations: Some(self.total_devices),
            features: vec![
                "nova_vulkan_support".to_string(),
                "opencl_support".to_string(),
                "multi_gpu".to_string(),
                "memory_management".to_string(),
                "compute_isolation".to_string(),
                "consensus_acceleration".to_string(),
                "quantum_security".to_string(),
                "power_monitoring".to_string(),
                "temperature_monitoring".to_string(),
            ],
        }
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use crate::assets::core::{SpaceProof, StakeProof, WorkProof, TimeProof, WorkloadType, WorkState};
    
    async fn create_test_gpu_request() -> AssetAllocationRequest {
        AssetAllocationRequest {
            asset_type: AssetType::Gpu,
            requested_resources: crate::assets::core::ResourceRequirements {
                gpu: Some(GpuRequirements {
                    units: 1,
                    min_memory_mb: Some(8192), // 8GB
                    compute_capability: Some("8.0".to_string()),
                    required_features: vec!["nova_vulkan_support".to_string()],
                }),
                ..Default::default()
            },
            privacy_level: PrivacyLevel::Private,
            consensus_proof: ConsensusProof::new(
                SpaceProof {
                    node_id: "test-node".to_string(),
                    storage_path: "/test/gpu".to_string(),
                    allocated_size: 8 * 1024 * 1024 * 1024,
                    proof_hash: vec![1, 2, 3, 4],
                    timestamp: SystemTime::now(),
                },
                StakeProof {
                    stake_holder: "test-holder".to_string(),
                    stake_holder_id: "test-holder-id".to_string(),
                    stake_amount: 500,
                    stake_timestamp: SystemTime::now(),
                },
                WorkProof {
                    worker_id: "test-worker".to_string(),
                    workload_id: "test-workload".to_string(),
                    process_id: 12345,
                    computational_power: 1000,
                    workload_type: WorkloadType::Compute,
                    work_state: WorkState::Completed,
                },
                TimeProof {
                    network_time_offset: Duration::from_secs(2),
                    time_verification_timestamp: SystemTime::now(),
                    nonce: 42,
                    proof_hash: vec![5, 6, 7, 8],
                },
            ),
            certificate_fingerprint: "test-cert".to_string(),
        }
    }
    
    #[tokio::test]
    async fn test_gpu_adapter_creation() {
        let adapter = GpuAssetAdapter::new().await;
        assert_eq!(adapter.asset_type(), AssetType::Gpu);
        assert!(adapter.total_devices > 0);
    }
    
    #[tokio::test]
    async fn test_gpu_allocation() {
        let adapter = GpuAssetAdapter::new().await;
        let request = create_test_gpu_request().await;
        
        let allocation = adapter.allocate_asset(&request).await.unwrap();
        assert_eq!(allocation.asset_id.asset_type, AssetType::Gpu);
        
        // Test deallocation
        adapter.deallocate_asset(&allocation.asset_id).await.unwrap();
    }
    
    #[tokio::test]
    async fn test_gpu_health_check() {
        let adapter = GpuAssetAdapter::new().await;
        let health = adapter.health_check().await.unwrap();
        
        assert!(health.healthy);
        assert!(health.performance_metrics.contains_key("total_devices"));
        assert!(health.performance_metrics.contains_key("total_memory_gb"));
    }
    
    #[tokio::test]
    async fn test_gpu_capabilities() {
        let adapter = GpuAssetAdapter::new().await;
        let capabilities = adapter.get_capabilities();
        
        assert_eq!(capabilities.asset_type, AssetType::Gpu);
        assert!(capabilities.supports_proxy_addressing);
        assert!(capabilities.features.contains(&"nova_vulkan_support".to_string()));
        assert!(capabilities.features.contains(&"consensus_acceleration".to_string()));
    }
}